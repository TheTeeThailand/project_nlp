{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab9701e-7ee6-4c4d-97fc-f58547d49d6a",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9662876b-afe3-4399-a7a4-3cf7a09e1598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d105f761-2179-424d-a466-98bd2160dee1",
   "metadata": {},
   "source": [
    "## Step 2: Load Pretrained Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "657ee403-5f91-486b-aac7-e1aefdf12e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/project_nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4b76d29a8c47fcb9ddc846b4901f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db532b97ee0417984ff10e60adfb38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571d030cb189484e9a033ad1965d5356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4e9eec69514550a67db0136540b922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained tokenizer and model (fine-tuned for sentiment)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Move model to CPU or GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e053259e-59d2-4ae2-b1c4-f52f433d0c2a",
   "metadata": {},
   "source": [
    "## Step 3: Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab4ee584-7528-41f8-a805-eadef7f11a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, max_length=64, device='cpu'):\n",
    "    \"\"\"\n",
    "    Predict sentiment of input text using DistilBERT model.\n",
    "\n",
    "    Args:\n",
    "        text (str): input sentence\n",
    "        model: Huggingface model\n",
    "        tokenizer: Huggingface tokenizer\n",
    "        max_length (int): token limit\n",
    "        device (str): 'cpu' or 'cuda'\n",
    "\n",
    "    Returns:\n",
    "        dict: {label: ..., confidence: ...}\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred_class = torch.argmax(probs, dim=1).item()\n",
    "        confidence = torch.max(probs).item()\n",
    "\n",
    "    label_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "    return {\n",
    "        \"label\": label_map[pred_class],\n",
    "        \"confidence\": round(confidence, 4)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa3d45-2a23-461e-ad8c-3f7589cf3a9e",
   "metadata": {},
   "source": [
    "## Step 4: Try Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f47c60e-2668-40aa-b388-c686611c647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I absolutely loved this movie. It was fantastic!\n",
      "Prediction: {'label': 'Positive', 'confidence': 0.9999}\n",
      "\n",
      "Text: The food was terrible and the service was slow.\n",
      "Prediction: {'label': 'Negative', 'confidence': 0.9998}\n",
      "\n",
      "Text: It's just okay, not good but not bad either.\n",
      "Prediction: {'label': 'Positive', 'confidence': 0.9954}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample texts to test\n",
    "texts = [\n",
    "    \"I absolutely loved this movie. It was fantastic!\",\n",
    "    \"The food was terrible and the service was slow.\",\n",
    "    \"It's just okay, not good but not bad either.\"\n",
    "]\n",
    "\n",
    "# Run predictions\n",
    "for text in texts:\n",
    "    result = predict_sentiment(text, model, tokenizer, device=device)\n",
    "    print(f\"Text: {text}\\nPrediction: {result}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_nlp",
   "language": "python",
   "name": "project_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
